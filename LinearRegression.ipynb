{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем выборку из цен на Бостон и реализуем линейную регресси методом наименьших квадратов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import scale\n",
    "from copy import deepcopy\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вытащим данные и разобьем выборку на обучающую и тестовую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karen/.local/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "data = load_boston()\n",
    "data_X = data.data\n",
    "data_y = data.target\n",
    "\n",
    "n = np.shape(data_X)[0]\n",
    "m = np.shape(data_X)[1]\n",
    "fix_data_X = np.empty((n, m + 1))\n",
    "fix_data_X[:, 0] = np.ones(n)\n",
    "fix_data_X[:, 1:] = np.random.randn(n, m)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(fix_data_X, data_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим функции для получения свободных коэффициентов СЛАУ, для получения матрицы основных коэффициентов, для получения матрицы, в которой k-ый (k пробегает значения по всем переменным) столбец заменен столбцом свободных коэффициентов, а также функцию для решения самой СЛАУ методом Крамера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.45376939, 23.44518487, 21.93770465, 19.83227104, 22.29583856,\n",
       "       22.48548365, 23.43627561, 20.00336048, 21.52854291, 24.65892953,\n",
       "       24.21954676, 24.28332321, 23.00243715, 21.58368213, 19.35228935,\n",
       "       24.05321094, 24.50147695, 21.33977585, 19.26686174, 23.50904154,\n",
       "       22.42337266, 20.46443165, 24.23524685, 20.84456625, 20.78131599,\n",
       "       22.99778839, 21.46990467, 23.11432856, 22.03906258, 22.21217269,\n",
       "       24.55914935, 22.22421642, 21.27161998, 23.78174732, 20.83336921,\n",
       "       23.02203075, 22.238321  , 20.20767276, 21.74463129, 23.34701892,\n",
       "       19.21740893, 20.91635932, 21.39462939, 23.52438283, 23.91843611,\n",
       "       22.49185585, 23.91206937, 23.77037886, 20.7625367 , 22.29285226,\n",
       "       20.96729452, 23.83079168, 22.91279107, 22.14267526, 22.38981012,\n",
       "       21.57653032, 21.98543894, 22.77338209, 21.08445239, 24.59087234,\n",
       "       23.98704482, 23.87967812, 24.9205008 , 20.22334193, 22.21094225,\n",
       "       22.90092837, 23.22019404, 21.50576385, 20.34671644, 22.49194389,\n",
       "       23.21252008, 21.54628438, 23.22719948, 24.46136169, 22.81343235,\n",
       "       23.09205053, 21.40330426, 22.88859528, 23.26441928, 21.18494719,\n",
       "       23.50156235, 21.69705578, 21.41938988, 23.28561264, 20.67912416,\n",
       "       22.68032699, 22.88341712, 21.48821856, 21.65647154, 24.45591535,\n",
       "       19.41611185, 22.16620065, 20.94664354, 24.4972269 , 23.33291627,\n",
       "       23.36126017, 27.08670536, 21.60089731, 21.89074346, 22.99288078,\n",
       "       24.46295728, 24.21584494])"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_b_coeffs(data_X, data_y):\n",
    "    b_coeffs = np.empty(m)\n",
    "    b_coeffs = np.matmul(data_y.transpose(), data_X)\n",
    "    return b_coeffs\n",
    "\n",
    "def get_a_coeffs(data_X, data_y):\n",
    "    a_coeffs = np.empty((m + 1, m + 1))\n",
    "    a_coeffs = np.matmul(data_X.transpose(), data_X)\n",
    "    return a_coeffs\n",
    "\n",
    "b_s = get_b_coeffs(data_X=X_train, data_y=y_train)\n",
    "a_s = get_a_coeffs(data_X=X_train, data_y=y_train)\n",
    "\n",
    "def get_matrix_k(a_coeffs, b_coeffs, k):\n",
    "    matrix = np.empty((m + 1, m + 1))\n",
    "    matrix = deepcopy(a_coeffs)\n",
    "    matrix[:, k] = b_coeffs\n",
    "    return matrix\n",
    "\n",
    "def solve_syst():\n",
    "    A = np.empty(m + 1)\n",
    "    for k in range(m + 1):\n",
    "        A[k] = np.linalg.det(get_matrix_k(a_s, b_s, k)) / np.linalg.det(a_s)\n",
    "    return A\n",
    "\n",
    "coeffs = solve_syst()\n",
    "y_pred = np.empty(len(y_test))\n",
    "y_pred = np.matmul(X_test, coeffs)\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
